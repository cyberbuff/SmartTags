The following article was originally published in “What I Learned This Week” on June 28, 2018. To learn more about 13D’s investment research, please visit our website.

Advanced processors customized for AI are converging with novel self-learning algorithms and robotics to take machine learning to the next level. The developments may disrupt incumbent chip producers while opening a potential door for China to build out its own semiconductor industry with new tech. A recent McKinsey study concludes AI-related technologies could add $3.5 trillion to $5.8 trillion annually to the global economy.
Consider the following:
		Next-generation AI chips will supercharge machine learning. In recent years, neural networks running on GPU (graphical processing units) chips, originally designed for video games, have produced major advances in AI as hardware accelerators to digest reams of data. Cloud computing has made it cheap to acquire enormous amounts of data, and businesses want to leverage it with AI. However, hardware has become a bottleneck as demand for processing power used in AI projects has been doubling every 3.5 months since 2012.



<img class="progressiveMedia-noscript js-progressiveMedia-inner" src="https://cdn-images-1.medium.com/max/1600/0*KLcS8HLq1cFwFC1W.png">
Source: The Economist
Three new AI chips hold promise:
		Graphcore — has designed an “intelligent processing unit” (IPU) combining processing and memory into one chip. In contrast, GPUs keep memory and processing separate, creating a bottleneck for data-heavy AI applications. Graphcore’s chip can hold entire neural networks, and has sent the “first batch [of chips] to customers.” “This is the first time we have had to reinvent compute from scratch since we invented it the first time about 75 years ago,” Graphcore CEO Nigel Toon says.
		IBM — has also created a chip combining memory and processing that is 280 times more energy-efficient than a GPU and can carry out 100 times as many operations per square millimeter. IBM’s chip is well suited to bring AI to personal devices and make data centers more efficient.
		Cerebras Systems — is in stealth mode, but goes even further with a systems approach to AI. CEO Andrew Feldman summarizes: “Big innovations are unlikely to come from a chip alone. They come from a system. To create the right technology for AI requires a systems approach — you must control the chip, the communication fabric, the printed circuit boards, the power and cooling delivery, the interfaces, the system software, and every aspect of the solution.”
		Breakthrough self-learning algorithms will allow AI to think more like humans. In recent issues, we have highlighted the disruptive potential of AlphaZero, the “tabula rasa” self-learning algorithm that acquired 1,500 years of human chess knowledge in just a few hours (see reports).
		Recently, DeepMind created a new algorithm that builds a mental picture of the world entirely by itself. Dubbed a “generative query network” (GQN), the system looks at a series of related 2D images from a camera, figures out the 3D environment, and predicts new views of the scene. In contrast to other AI vision systems, DeepMind’s GQN makes sense of a scene more the way a person does, and can reason on what is there even if something is partly excluded.
		GQN learns similar to how humans learn and holds the promise to be a foundation for deeper AI-enabling machines to navigate the world and reason with growing sophistication. For instance, GQN systems can analyze 2D views and control a digital robotic arm to navigate the real world.
		The approach has the potential to “unshackle” deep learning systems from the “labeled data” requirement. GQN is the first step to “unsupervised transfer learning,” giving a machine the ability to figure out the goal based on raw input data alone, without requiring additional data from human supervisors, according to a SingularityHubanalysis.
		AI that can interact with the real world may be a game changer. Up until now, AI and robotics have been separate fields, highlights a recent MIT Technology Review report. AI has largely existed inside computers, interacting with simulations of the real world, while robots were largely pre-programmed with simple software to do specific tasks.
		Deep-learning expert Yann LeCun believes combining AI and robotics is key to taking the technology to the next level. In order for AI to reason and take action, AI needs a physical presence. Human intelligence involves interacting with the real world, and AI embedded in robots can achieve similar results. “A lot of the most interesting AI research now involves robots,” says LeCun.
		For instance, early versions of Boston Dynamics Atlas robot were tethered by cable for power and cooling water. Now, Atlas is untethered and autonomous, capable of performing backflips (see video here), continually improving itself with proprietary algorithms.
		A machine revolution could be unfolding, mirroring the process that drove biological intelligence. Recently, San Francisco startup Osaro unveiled an AI-controlled robot used for chicken processing that outperforms humans. The AI software enables the robot to identify objects in front of it, examine how they behave and determine how to proceed.
		“If you solve manipulation in its fullest, you’ll probably have built something that’s pretty close to full, human-level intelligence,” notes Pieter Abbeel, a professor at the University of California, Berkeley and founder of Embodied Intelligence, which is applying machine learning and virtual reality to robotics.
		The economics of AI are on the cusp of permeating every level of the global economy. After examining 400 use cases across 19 industries and nine business functions, McKinsey found that two-thirds of AI’s current opportunities are in analytics. Examples include predictive maintenance, detecting anomalies, logistics optimization, and improving customer-service management and personalized marketing. The chart below shows the impact of AI on a range of industries.

New AI applications are proliferating. In just the last week, it was reported that Google’s AI tools can now predict death risks more accurately than hospitals, AI can help cities forecast natural disasters, and Japan may use an AI-based crime prediction system.
		The accelerating decline in the “cost of prediction” will lead to new business models. A simple analogy is the “app economy.” As the cost of computing declined and cognitive capabilities increased, the creation of the iPhone in 2007 led to the formation of the “app economy.” This new industry will be worth $6.3 trillion by 2021, up from $1.3 trillion last year, as the user base nearly doubles form 3.4 billion people now to 6.3 billion, concludes a study by app analytics firm App Annie.
		Initially, AI is being deployed for traditional prediction problems such as inventory management. However, AI is now beginning to solve problems that haven’t historically been considered “prediction problems,” according to University of Toronto professors Ajay Agrawal, Joshua Gans, and Avi Goldfarb in Prediction Machines: The Simple Economics of Artificial Intelligence. Autonomous vehicles are a key example. Engineers traditionally programmed an autonomous vehicle to operate in a controlled environment, such as a factory. Now, for uncontrolled environments such as city streets the algorithms can ask “What would a good human driver do?